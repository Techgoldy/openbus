[main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://localhost.localdomain:8020
[main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://192.168.72.134:8020
[main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to map-reduce job tracker at: 192.168.72.134:8021
[main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.CombinerOptimizer  - Choosing to move algebraic foreach to combiner
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 1
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 1
[main] WARN  org.apache.pig.backend.hadoop23.PigJobControl  - falling back to default JobControl (not using hadoop 0.23 ?)
java.lang.NoSuchFieldException: jobsInProgress
	at java.lang.Class.getDeclaredField(Class.java:1884)
	at org.apache.pig.backend.hadoop23.PigJobControl.<clinit>(PigJobControl.java:58)
	at org.apache.pig.backend.hadoop.executionengine.shims.HadoopShims.newJobControl(HadoopShims.java:102)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.compile(JobControlCompiler.java:285)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:177)
	at org.apache.pig.PigServer.launchPlan(PigServer.java:1266)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1251)
	at org.apache.pig.PigServer.execute(PigServer.java:1241)
	at org.apache.pig.PigServer.access$400(PigServer.java:123)
	at org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1554)
	at org.apache.pig.PigServer.registerQuery(PigServer.java:518)
	at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:991)
	at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:412)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:194)
	at org.apache.pig.PigServer.registerScript(PigServer.java:592)
	at org.apache.pig.PigServer.registerScript(PigServer.java:694)
	at org.apache.pig.PigServer.registerScript(PigServer.java:657)
	at pigconnector.PigTest.main(PigTest.java:20)
[main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig script settings are added to the job
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator  - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=-1
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Could not estimate number of reducers and no requested or default parallelism set. Defaulting to 1 reducer.
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - creating jar file Job729329952989152198.jar
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - jar file Job729329952989152198.jar created
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
[main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
[main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
[main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
[main] WARN  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Ooops! Some job has failed! Specify -stop_on_failure if you want Pig to stop immediately on failure.
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - job null has failed! Stop running all dependent jobs
[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
[main] WARN  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.Launcher  - There is no log file to write to.
[main] ERROR org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.Launcher  - Backend error message during job submission
java.lang.IllegalArgumentException: java.net.UnknownHostException: localhost.localdomain
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:414)
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:164)
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:129)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:448)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:410)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:128)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2308)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:87)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2342)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2324)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:351)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:194)
	at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:103)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:951)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:945)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:945)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:566)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:319)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.startReadyJobs(JobControl.java:239)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run(JobControl.java:270)
	at org.apache.pig.backend.hadoop23.PigJobControl.run(PigJobControl.java:160)
	at java.lang.Thread.run(Thread.java:662)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:257)
Caused by: java.net.UnknownHostException: localhost.localdomain
	... 26 more

[main] ERROR org.apache.pig.tools.pigstats.SimplePigStats  - ERROR: java.net.UnknownHostException: localhost.localdomain
[main] ERROR org.apache.pig.tools.pigstats.PigStatsUtil  - 1 map reduce job(s) failed!
[main] INFO  org.apache.pig.tools.pigstats.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.0.0-mr1-cdh4.4.0	0.11.0-cdh4.4.0	mmesa	2014-05-20 10:52:47	2014-05-20 10:52:54	GROUP_BY

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
N/A	A,B,C,D	GROUP_BY,COMBINER	Message: java.lang.IllegalArgumentException: java.net.UnknownHostException: localhost.localdomain
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:414)
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:164)
	at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:129)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:448)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:410)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:128)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2308)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:87)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2342)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2324)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:351)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:194)
	at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:103)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:951)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:945)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:945)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:566)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:319)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.startReadyJobs(JobControl.java:239)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run(JobControl.java:270)
	at org.apache.pig.backend.hadoop23.PigJobControl.run(PigJobControl.java:160)
	at java.lang.Thread.run(Thread.java:662)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:257)
Caused by: java.net.UnknownHostException: localhost.localdomain
	... 26 more
	hdfs://192.168.72.134:8020/user/mmesa/wordcount,

Input(s):
Failed to read data from "hdfs://192.168.72.134:8020/user/mmesa/input.txt"

Output(s):
Failed to produce result in "hdfs://192.168.72.134:8020/user/mmesa/wordcount"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
null


[main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
